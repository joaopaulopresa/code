{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import shutil\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Dataset Description\n",
       "# Tax Law Brazil Cosit Dataset\n",
       "\n",
       "\n",
       "Our dataset consists of a series of tax law questions related to legal entities. The questions were selected from a collection that is annually updated by the General Coordination of Taxation (Cosit). \n",
       "https://www.gov.br/receitafederal/pt-br/assuntos/orientacao-tributaria/declaracoes-e-demonstrativos/ecf/perguntas-e-respostas-pj-2023.pdf \n",
       "Accessed: 11/11/2023\n",
       "\n",
       "## Dataset Features\n",
       "- **question**: The tax-related question.\n",
       "- **answer**: The official answer to the tax-related question.\n",
       "- **reference**: The specific normative reference related to the question.\n",
       "- **gold_passage**: The gold passage or specific reference text related to the question.\n",
       "- **corpus_documents**: Content of the related documents in the corpus.\n",
       "\n",
       "## Dataset Splits\n",
       "```python\n",
       "DatasetDict({\n",
       "    tax_law: Dataset({\n",
       "        features: ['question', 'answer', 'reference', 'gold_passage'],\n",
       "        num_rows: 101\n",
       "    })\n",
       "    corpus: Dataset({\n",
       "        features: ['document_id', 'content'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})\n",
       "```\n",
       "\n",
       "## Sample row from 'tax_law' split\n",
       "```python\n",
       "{'question': 'Que pessoas jurídicas estão desobrigadas de apresentar a ECF?', 'answer': 'Estão desobrigadas de apresentar a ECF: I - as pessoas jurídicas optantes pelo Regime Especial Unificado de Arrecadação de Tributos e Contribuições devidos pelas Microempresas e Empresas de Pequeno Porte, instituído pela Lei Complementar nº 123, de 14 de dezembro de 2006 (Simples Nacional), por estarem obrigadas à apresentação de Declaração Anual do Simples Nacional - DASN; II - os órgãos públicos, as autarquias e as fundações públicas; e III - as pessoas jurídicas inativas, assim consideradas aquelas que não tenham efetuado qualquer atividade operacional, não operacional, patrimonial ou financeira, inclusive aplicação no mercado financeiro ou de capitais, durante todo o ano-calendário, as quais deverão cumprir as obrigações acessórias previstas na legislação específica.', 'reference': 'IN RFB nº 2.004, de 2021, art. 1º, § 1º;', 'gold_passage': 'Art. 1º A Escrituração Contábil Fiscal (ECF) será apresentada, a partir do ano-calendário de 2014, por todas as pessoas jurídicas, inclusive as equiparadas, de forma centralizada pela matriz, de acordo com as regras estabelecidas nesta Instrução Normativa.\\r\\n§ 1º A obrigatoriedade a que se refere o caput não se aplica:\\r\\nI - às pessoas jurídicas optantes pelo Regime Especial Unificado de Arrecadação de Tributos e Contribuições devidos pelas Microempresas e Empresas de Pequeno Porte (Simples Nacional), de que trata a Lei Complementar nº 123, de 14 de dezembro de 2006;\\r\\nII - aos órgãos públicos, às autarquias e às fundações públicas; e\\r\\nIII - às pessoas jurídicas inativas, assim consideradas aquelas que não tenham efetuado qualquer atividade operacional, não operacional, patrimonial ou financeira, inclusive aplicação no mercado financeiro ou de capitais, durante todo o ano-calendário, as quais devem cumprir as obrigações acessórias previstas na legislação específica.\\r\\n§ 2º Para as pessoas jurídicas que apuram o Imposto sobre a Renda das Pessoas Jurídicas (IRPJ) pela sistemática do lucro real, a ECF é o Livro de Apuração do Lucro Real a que se refere o inciso I do caput do art. 8º do Decreto-Lei nº 1.598, de 26 de dezembro de 1977.\\r\\n§ 3º No caso de pessoas jurídicas sócias ostensivas de Sociedades em Conta de Participação (SCP), a ECF deverá ser transmitida separadamente, para cada SCP, além da transmissão da ECF da sócia ostensiva.'}\n",
       "```\n",
       "\n",
       "## Sample document from 'corpus' split\n",
       "#### Decreto-Lei nº 1.598, de 1977.txt:\n",
       "DECRETO-LEI Nº 1.598, DE 26 DE DEZEMBRO DE 1977.\n",
       "\n",
       "Vigência\t\n",
       "Altera a legislação do imposto sobre a renda.\n",
       "\n",
       "        O PRESIDENTE DA REPÚBLICA , no uso das atribuições que lhe confere o artigo 55, item II, da Constituição, e tendo em vista a necessidade de adaptar a legislação do imposto sobre a renda às inovações da lei de sociedades por ações (Lei nº 6.404, de 15 de dezembro de 1976),\n",
       "\n",
       "        DECRETA:\n",
       "\n",
       "        Art 1º - O imposto sobre o lucro das pessoas jurídicas domiciliadas no País, inclusiv..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Define the file paths\n",
    "output_dataset_dir = 'tax_law_brazil_cosit'\n",
    "readme_path = f'{output_dataset_dir}/README.md'\n",
    "\n",
    "# Load the dataset from disk\n",
    "dataset_dict = load_from_disk(output_dataset_dir)\n",
    "\n",
    "# Read the description and features from README.md\n",
    "with open(readme_path, 'r', encoding='utf-8') as file:\n",
    "    readme_content = file.read()\n",
    "\n",
    "# Split the README content into description and features\n",
    "description, features_section = readme_content.split(\"## Features\", 1)\n",
    "\n",
    "# Prepare the markdown content\n",
    "markdown_content = []\n",
    "\n",
    "markdown_content.append(\"# Dataset Description\")\n",
    "markdown_content.append(description.strip())\n",
    "\n",
    "markdown_content.append(\"\\n## Dataset Features\")\n",
    "markdown_content.append(features_section.strip())\n",
    "\n",
    "# Print the splits\n",
    "markdown_content.append(\"\\n## Dataset Splits\")\n",
    "markdown_content.append(f\"```python\\n{dataset_dict}\\n```\")\n",
    "\n",
    "# Print one row from the tax_law split\n",
    "markdown_content.append(\"\\n## Sample row from 'tax_law' split\")\n",
    "markdown_content.append(f\"```python\\n{dataset_dict['tax_law'][0]}\\n```\")\n",
    "\n",
    "# Print one document from the corpus split\n",
    "markdown_content.append(\"\\n## Sample document from 'corpus' split\")\n",
    "markdown_content.append(f\"#### {dataset_dict['corpus']['document_id'][0]}:\\n{dataset_dict['corpus']['content'][0][:500]}...\")\n",
    "\n",
    "# Combine the markdown content into a single string\n",
    "markdown_output = \"\\n\".join(markdown_content)\n",
    "\n",
    "# Display the markdown content\n",
    "display(Markdown(markdown_output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Question Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_template = \"\"\"Use the following pieces of legal information from laws to answer the user's question.\n",
    "If the answer is not clear in context, try to figure out by interpreting the information.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Do not quote the \"contextual information\" provided in the answer, do not say \"according to the information\" or anything like that, use the information only to answer the question.\n",
    "Only return the helpful answer below and nothing else.\n",
    "REMEMBER: answer the question in portuguese.\n",
    "Helpful answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(retriever_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
    "               'mistralai/Mistral-7B-Instruct-v0.2',\n",
    "               'zero-one-ai/Yi-34B-Chat',\n",
    "               'garage-bAInd/Platypus2-70B-instruct',\n",
    "               'google/gemma-7b-it',\n",
    "               'lmsys/vicuna-13b-v1.5',\n",
    "               'lmsys/vicuna-7b-v1.5',\n",
    "               'meta-llama/Llama-2-70b-chat-hf',\n",
    "               'meta-llama/Llama-2-13b-chat-hf',\n",
    "               'meta-llama/Llama-2-7b-chat-hf',\n",
    "               'openchat/openchat-3.5-1210',\n",
    "               'WizardLM/WizardLM-13B-V1.2',\n",
    "               'Qwen/Qwen1.5-14B-Chat',\n",
    "               'Qwen/Qwen1.5-72B-Chat',\n",
    "               'upstage/SOLAR-10.7B-Instruct-v1.0',\n",
    "               'meta-llama/Llama-3-70b-chat-hf',\n",
    "               'mistralai/Mistral-7B-Instruct-v0.3',\n",
    "               'mistralai/Mixtral-8x22B-Instruct-v0.1',\n",
    "               'meta-llama/Llama-3-8b-chat-hf',\n",
    "               'Qwen/Qwen2-72B-Instruct',\n",
    "               'Qwen/Qwen1.5-110B-Chat',\n",
    "               'teknium/OpenHermes-2p5-Mistral-7B',\n",
    "               'openia/gpt-3.5-turbo'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with Mixtral-8x7B-Instruct-v0.1: 100%|██████████| 101/101 [00:00<00:00, 55960.99it/s]\n",
      "Processing with Mistral-7B-Instruct-v0.2: 100%|██████████| 101/101 [00:00<00:00, 39228.14it/s]\n",
      "Processing with Yi-34B-Chat: 100%|██████████| 101/101 [00:00<00:00, 52853.99it/s]\n",
      "Processing with Platypus2-70B-instruct: 100%|██████████| 101/101 [00:00<00:00, 54774.33it/s]\n",
      "Processing with gemma-7b-it: 100%|██████████| 101/101 [00:00<00:00, 54703.60it/s]\n",
      "Processing with vicuna-13b-v1.5: 100%|██████████| 101/101 [00:00<00:00, 42929.13it/s]\n",
      "Processing with vicuna-7b-v1.5: 100%|██████████| 101/101 [00:00<00:00, 53266.03it/s]\n",
      "Processing with Llama-2-70b-chat-hf: 100%|██████████| 101/101 [00:00<00:00, 56453.19it/s]\n",
      "Processing with Llama-2-13b-chat-hf: 100%|██████████| 101/101 [00:00<00:00, 58902.21it/s]\n",
      "Processing with Llama-2-7b-chat-hf: 100%|██████████| 101/101 [00:00<00:00, 10287.65it/s]\n",
      "Processing with openchat-3.5-1210: 100%|██████████| 101/101 [00:00<00:00, 55267.41it/s]\n",
      "Processing with WizardLM-13B-V1.2: 100%|██████████| 101/101 [00:00<00:00, 53827.79it/s]\n",
      "Processing with Qwen1.5-14B-Chat: 100%|██████████| 101/101 [00:00<00:00, 58166.24it/s]\n",
      "Processing with Qwen1.5-72B-Chat: 100%|██████████| 101/101 [00:00<00:00, 55130.75it/s]\n",
      "Processing with SOLAR-10.7B-Instruct-v1.0: 100%|██████████| 101/101 [00:00<00:00, 48226.86it/s]\n",
      "Processing with Llama-3-70b-chat-hf: 100%|██████████| 101/101 [00:00<00:00, 53684.54it/s]\n",
      "Processing with Mistral-7B-Instruct-v0.3: 100%|██████████| 101/101 [00:00<00:00, 43542.47it/s]\n",
      "Processing with Mixtral-8x22B-Instruct-v0.1: 100%|██████████| 101/101 [00:00<00:00, 51304.92it/s]\n",
      "Processing with Llama-3-8b-chat-hf: 100%|██████████| 101/101 [00:00<00:00, 55688.80it/s]\n",
      "Processing with Qwen2-72B-Instruct: 100%|██████████| 101/101 [00:00<00:00, 58270.25it/s]\n",
      "Processing with Qwen1.5-110B-Chat: 100%|██████████| 101/101 [00:00<00:00, 48787.83it/s]\n",
      "Processing with OpenHermes-2p5-Mistral-7B: 100%|██████████| 101/101 [00:00<00:00, 53800.45it/s]\n",
      "Processing with gpt-3.5-turbo: 100%|██████████| 101/101 [00:00<00:00, 46470.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for model in models:\n",
    "    if model == 'openai/gpt-3.5-turbo':\n",
    "        llm = ChatOpenAI(\n",
    "            temperature=0.1,\n",
    "            model='gpt-3.5-turbo',\n",
    "        )\n",
    "    else:\n",
    "        llm = ChatOpenAI(\n",
    "            base_url=\"https://api.together.xyz/v1\",\n",
    "            temperature=0.1,\n",
    "            api_key=os.getenv('TOGETHER_API_KEY'),\n",
    "            model=model,\n",
    "        )\n",
    "    \n",
    "    output_parser = StrOutputParser()\n",
    "    chain = prompt | llm | output_parser\n",
    "    data = []\n",
    "\n",
    "    for row in tqdm(dataset_dict['tax_law'], desc=f\"Processing with {model.split('/')[1]}\"):\n",
    "        question = row['question']\n",
    "        gold_passage = row['gold_passage']\n",
    "        answer = row['answer']\n",
    "        model_answer = chain.invoke({'context': gold_passage, 'question': question})\n",
    "        data.append([question, answer, model_answer])\n",
    "\n",
    "    df_m = pd.DataFrame(columns=['Q', 'A', 'A_model'], data=data)\n",
    "    df_m.to_csv(f'result_question_answer_generation/{model.split('/')[1]}_QAG.csv', index=False)\n",
    "\n",
    "print('Finish')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
